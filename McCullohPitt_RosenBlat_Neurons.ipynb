{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "McCullohPitt_RosenBlat_Neurons.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP28yAfp8IMNEP3zzO2ggeZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasantbala/vb_ai_course/blob/main/McCullohPitt_RosenBlat_Neurons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO11H6Z6dxWa"
      },
      "source": [
        "from random import choice\r\n",
        "from numpy import array, dot, random\r\n",
        "\r\n",
        "import numpy as np;\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqNC-AByeLUy",
        "outputId": "d671099b-7aed-4c6e-e935-2d334c92daec"
      },
      "source": [
        "# MCNeuron for And\r\n",
        "\r\n",
        "w = random.rand(2)\r\n",
        "w[1] = 1\r\n",
        "w[0] = 1\r\n",
        "\r\n",
        "training_data = [\r\n",
        "      (array([0,0]), 0),\r\n",
        "      (array([0,1]), 0),\r\n",
        "      (array([1,0]), 0),\r\n",
        "      (array([1,1]), 1)\r\n",
        "]\r\n",
        "\r\n",
        "step_function = lambda x: 0 if x < 2 else 1\r\n",
        "\r\n",
        "for x, _ in training_data:\r\n",
        "  result = dot(x,w)\r\n",
        "  print(\"{}: {} -> {}\".format(x[:2], result, step_function(result)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0]: 0.0 -> 0\n",
            "[0 1]: 1.0 -> 0\n",
            "[1 0]: 1.0 -> 0\n",
            "[1 1]: 2.0 -> 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcCWGeYxew_N",
        "outputId": "06354b66-37d6-49c7-8d74-d4013e17891e"
      },
      "source": [
        "# MCNeuron for Or\r\n",
        "\r\n",
        "w = random.rand(2)\r\n",
        "w[1] = 1\r\n",
        "w[0] = 1\r\n",
        "\r\n",
        "training_data = [\r\n",
        "      (array([0,0]), 0),\r\n",
        "      (array([0,1]), 1),\r\n",
        "      (array([1,0]), 1),\r\n",
        "      (array([1,1]), 1)\r\n",
        "]\r\n",
        "\r\n",
        "step_function = lambda x: 0 if x < 1 else 1\r\n",
        "\r\n",
        "for x, _ in training_data:\r\n",
        "  result = dot(x,w)\r\n",
        "  print(\"{}: {} -> {}\".format(x[:2], result, step_function(result)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0]: 0.0 -> 0\n",
            "[0 1]: 1.0 -> 1\n",
            "[1 0]: 1.0 -> 1\n",
            "[1 1]: 2.0 -> 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1BtLwvifEdy",
        "outputId": "0a64d68c-5eec-40e7-e366-59ee6f6c653a"
      },
      "source": [
        "# MCNeuron for NAND\r\n",
        "\r\n",
        "w[1] = 1\r\n",
        "w[0] = 1\r\n",
        "\r\n",
        "training_data = [\r\n",
        "    (array([0,0]), 1),\r\n",
        "    (array([0,1]), 1),\r\n",
        "    (array([1,0]), 1),\r\n",
        "    (array([1,1]), 0),\r\n",
        "]\r\n",
        "\r\n",
        "step_function = lambda x: 0 if x > 1 else 1\r\n",
        "\r\n",
        "for x, _ in training_data:\r\n",
        "    result = dot(x, w)\r\n",
        "\r\n",
        "    print(\"{}: {} -> {}\".format(x[:2], result, step_function(result)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0]: 0.0 -> 1\n",
            "[0 1]: 1.0 -> 1\n",
            "[1 0]: 1.0 -> 1\n",
            "[1 1]: 2.0 -> 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1JHjbYrfc3c"
      },
      "source": [
        "# Rosenblat's Perceptron included a way to adjust the weights and find the appropriate combinations \r\n",
        "# to overcome the need to modify thresholds for each gate separately, it used a bias term using which the thresholds in the \r\n",
        "# neuron can be modified to implement multiple Boolean functions in one code"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBbfnnEmfjCX",
        "outputId": "688ec1c2-669c-4b00-e6c3-85ca339ccb19"
      },
      "source": [
        "step_function = lambda x: 0 if x < 100 else 1    # Step function with threshold of 0.5. Anything below is 0 \r\n",
        "\r\n",
        "\r\n",
        "# AND gate\r\n",
        "training_data = [\r\n",
        "    (array([0,0 ,1]), 0),\r\n",
        "    (array([0,1, 1]), 0),\r\n",
        "    (array([1,0, 1]), 0),\r\n",
        "    (array([1,1, 1]), 1),\r\n",
        "]\r\n",
        "\r\n",
        "w = random.rand(3)\r\n",
        "print(w)\r\n",
        "\r\n",
        "errors = []\r\n",
        "eta = 0.1\r\n",
        "n = 100000\r\n",
        "\r\n",
        "for i in range(n):\r\n",
        "    x, expected = choice(training_data)\r\n",
        "\r\n",
        "\r\n",
        "    result = dot(w, x)\r\n",
        "    error = expected - step_function(result)   # irrespective of what threshold we set, the algo will find the approp weights\r\n",
        "    errors.append(error)                       # that is the beauty of bias. The 'AND' pattern is learnt from data\r\n",
        "    w += eta * error * x\r\n",
        "\r\n",
        "for x, _ in training_data:\r\n",
        "    result = dot(x, w)\r\n",
        "    print(\"{}: {} -> {}\".format(x[:3], result, step_function(result)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.57935803 0.24777385 0.98726314]\n",
            "[0 0 1]: 33.787263136671136 -> 0\n",
            "[0 1 1]: 66.83503698216288 -> 0\n",
            "[1 0 1]: 67.16662116662741 -> 0\n",
            "[1 1 1]: 100.21439501211916 -> 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQinqUlsfyAe",
        "outputId": "f256a001-5a13-4ad4-d56c-e5fca9cadbb9"
      },
      "source": [
        "step_function = lambda x: 0 if x < 100 else 1    # Step function with threshold of 0.5. Anything below is 0 \r\n",
        "\r\n",
        "\r\n",
        "# OR gate\r\n",
        "training_data = [\r\n",
        "    (array([0,0 ,1]), 0),\r\n",
        "    (array([0,1, 1]), 1),\r\n",
        "    (array([1,0, 1]), 1),\r\n",
        "    (array([1,1, 1]), 1),\r\n",
        "]\r\n",
        "\r\n",
        "w = random.rand(3)\r\n",
        "print(w)\r\n",
        "\r\n",
        "errors = []\r\n",
        "eta = 0.1\r\n",
        "n = 100000\r\n",
        "\r\n",
        "for i in range(n):\r\n",
        "    x, expected = choice(training_data)\r\n",
        "\r\n",
        "\r\n",
        "    result = dot(w, x)\r\n",
        "    error = expected - step_function(result)   # irrespective of what threshold we set, the algo will find the approp weights\r\n",
        "    errors.append(error)                       # that is the beauty of bias. The 'AND' pattern is learnt from data\r\n",
        "    w += eta * error * x\r\n",
        "\r\n",
        "for x, _ in training_data:\r\n",
        "    result = dot(x, w)\r\n",
        "    print(\"{}: {} -> {}\".format(x[:3], result, step_function(result)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.74425456 0.41239391 0.64497321]\n",
            "[0 0 1]: 62.74497321196064 -> 0\n",
            "[0 1 1]: 100.15736712644593 -> 1\n",
            "[1 0 1]: 102.189227772386 -> 1\n",
            "[1 1 1]: 139.60162168687128 -> 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubavMzTpf_yq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}